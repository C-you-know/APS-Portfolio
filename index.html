<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="A simple static web page template with GitHub-inspired dark styling, focusing on course information and an introduction to Klein and its architecture.">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <link rel="icon" type="image/svg+xml" href="Klein_Logo.png">
    <img src="Klein_Logo.svg" alt="Logo" style="height: 1.2em; vertical-align: middle; margin-right: 0.5em;">
    <title>Meet Klein</title>
    <link rel="stylesheet" href="index.css">
</head>
<body>
    <header role="banner">
        <h1>Meet Klein</h1>
    </header>
    <main role="main">
        <section aria-labelledby="course-info-heading">
            <h2 id="course-info-heading">Course Information</h2>
            <p><strong>Course Name:</strong> Algorithmic Problem Solving</p>
            <p><strong>Domain:</strong> Distributed AI Model Serving and Inference Infrastructure</p>
            <p><strong>Course Code:</strong> 24ECSE309</p>
            <p><strong>Faculty:</strong> Prakash Hegade</p>
            <p><strong>University:</strong> KLE Technological University, Hubballi-31</p>
        </section>

        <section aria-labelledby="introduction-heading">
            <h2 id="introduction-heading">Introduction</h2>
            <p>We are building a globally distributed AI inference platform that serves machine learning models with high availability, low latency, and automatic scalability. It supports multi-tenant deployments, dynamically allocating GPUs based on model demand. A hierarchical load balancing system routes requests from users to regions, then to optimal GPU nodes. All inference inputs and outputs are stored for traceability, and stateless compute with replicated storage ensures fault tolerance. The platform handles diverse input types (text, images, video, audio, time series) and scales horizontally and vertically to match workload fluctuations.</p>
        </section>

        <section aria-labelledby="requirements-heading">
            <h2 id="requirements-heading">System Properties</h2>
            <ul>
                <li>Distributed Worldwide Access</li>
                <li>Highly Available</li>
                <li>Horizontally and Vertically Scalable</li>
                <li>Low Latency</li>
                <li>Observability</li>
                <li>Security and Access Control</li>
            </ul>
        </section>

        <section aria-labelledby="industries-heading">
            <h2 id="industries-heading">Industries & Use Cases</h2>
            <ul>
                <li><strong>E-Commerce:</strong> Real-time recommendations, fraud detection, image-based search</li>
                <li><strong>Healthcare:</strong> Diagnostic AI (X-rays, MRIs), remote patient monitoring</li>
                <li><strong>Autonomous Vehicles:</strong> Object detection, path prediction, fleet inference</li>
                <li><strong>Social Media:</strong> Content moderation, feed ranking, voice/video filters</li>
                <li><strong>AI-as-a-Service:</strong> Multi-tenant model hosting, usage-based billing</li>
                <li><strong>Finance:</strong> Fraud detection, market prediction, document OCR</li>
                <li><strong>Gaming:</strong> AI NPCs, real-time voice translation, behavior modeling</li>
                <li><strong>Manufacturing/IoT:</strong> Sensor anomaly detection, predictive maintenance</li>
                <li><strong>Telecom:</strong> Network optimization, voice assistant services</li>
                <li><strong>Security/Surveillance:</strong> Face recognition, activity detection</li>
            </ul>
        </section>

        <section aria-labelledby="architecture-heading">
            <h2 id="architecture-heading">Architecture</h2>
            <p>In today's world of rapidly evolving AI models and increasing demand, traditional single-server inference setups are insufficient. Distributing AI model serving across multiple nodes and regions becomes essential to achieve high availability, handle large traffic volumes with low latency, and ensure fault tolerance. A distributed architecture allows dynamic scaling, efficient resource utilization (like GPUs), and resilience against failures, providing a robust foundation for serving AI models globally.</p>
            <img src="src/Klein_Arch.jpeg" height="500px" width="850px" alt="Architecture diagram of the Klein platform">
        </section>

        <section aria-labelledby="content-list-heading">
            <h2 id="content-list-heading">Explore Key Concepts</h2>
            <ul>
                <li><a href="content/distributed-load-balancing.html">Distributed Load Balancing</a></li>
                <li><a href="content/rate-limiting.html">Rate Limiting and Backpressure</a></li>
                <li><a href="content/multi-tenant-gpu.html">Multi-tenant GPU Allocation</a></li>
                <li><a href="content/model-versioning.html">Merkle Tree Model Versioning</a></li>
                <li><a href="content/content-addressed-storage.html">Content-Addressed Storage & Bloom Filters</a></li>
                <li><a href="content/monitoring-alerting.html">Monitoring & Alerting</a></li>
                <li><a href="content/security.html">Security and Access Control</a></li>
                <li><a href="content/trace-compression.html">Trace Storage Compression</a></li>
                <li><a href="content/communication-protocols.html">Communication Protocols</a></li>
                <li><a href="content/lsm-tree.html">LSM Tree for Write Optimized Caches</a></li>
                <li><a href="content/load-prediction.html">Dynamic Load Prediction</a></li>
            </ul>
        </section>

        <section aria-labelledby="student-details-heading">
            <h2 id="student-details-heading">Student Details</h2>
            <p><strong>Name:</strong> Chinmay J S</p>
            <p><strong>Branch:</strong> CSAI</p>
            <p><strong>USN:</strong> 01FE22BCI351</p>
            <p><strong>College:</strong> KLE Technological University, Hubballi</p>
            <p><strong>Roll:</strong> 164</p>
        </section>

    </main>
    <footer role="contentinfo">
        <p>Â© 2025 Klein. All rights reserved.</p>
    </footer>
</body>
</html>